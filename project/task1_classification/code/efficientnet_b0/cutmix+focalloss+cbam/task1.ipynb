{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models  \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm, trange\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\images\"\n",
    "    label_csv = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\labels.csv\"\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 60\n",
    "    lr = 5e-5  \n",
    "    num_workers = 0 \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = \"efficientnet_b0\"  \n",
    "    save_dir = \"./output\"\n",
    "    seed = 42\n",
    "\n",
    "torch.manual_seed(Config.seed)\n",
    "os.makedirs(Config.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d05810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df      = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.train   = train\n",
    "        \n",
    "        if self.train:\n",
    "            self.transform = get_transforms(train=True)\n",
    "        else:\n",
    "            self.transform = get_transforms(train=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row      = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        # 1) è¯»å›¾å¹¶è½¬æˆ numpy\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        # 2) ç»Ÿä¸€ transform\n",
    "        image = self.transform(image=image)['image']  # å·²ç»æ˜¯ Tensor, CÃ—HÃ—W\n",
    "        # 3) å–æ ‡ç­¾\n",
    "        label = int(row['label'])\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"\n",
    "    CutMix éšæœºç”Ÿæˆä¸€ä¸ªçŸ©å½¢æ¡†ã€‚\n",
    "    size: tuple (W, H)\n",
    "    lam: ä» Beta åˆ†å¸ƒä¸­é‡‡æ ·çš„ Î»\n",
    "    è¿”å› (x0, y0, x1, y1)\n",
    "    \"\"\"\n",
    "    W, H = size\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # éšæœºä¸­å¿ƒ\n",
    "    cx = random.randint(0, W)\n",
    "    cy = random.randint(0, H)\n",
    "\n",
    "    x0 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    y0 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    x1 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "class MixUpCollator:\n",
    "    def __init__(self, alpha=0.4, prob=0.5):\n",
    "        \"\"\"\n",
    "        alpha: MixUp Beta åˆ†å¸ƒå‚æ•°\n",
    "        prob: æ¯ä¸ª batch åº”ç”¨ MixUp çš„æ¦‚ç‡\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.prob  = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of (image_tensor, label)\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)                          # [B, C, H, W]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).view(-1,1)  # [B, 1]\n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        idx = torch.randperm(images.size(0))\n",
    "        mixed_images = lam * images + (1. - lam) * images[idx]\n",
    "        mixed_labels = lam * labels + (1. - lam) * labels[idx]\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "class CutMixCollator:\n",
    "    def __init__(self, beta=1.0, prob=0.5):\n",
    "        \"\"\"\n",
    "        beta: CutMix Beta åˆ†å¸ƒå‚æ•°\n",
    "        prob: æ¯ä¸ª batch åº”ç”¨ CutMix çš„æ¦‚ç‡\n",
    "        \"\"\"\n",
    "        self.beta = beta\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)                          \n",
    "        labels = torch.tensor(labels, dtype=torch.float32).view(-1,1)  \n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        idx = torch.randperm(images.size(0))\n",
    "\n",
    "        # éšæœºè£æ¡†\n",
    "        _, C, H, W = images.shape\n",
    "        x0, y0, x1, y1 = rand_bbox((W, H), lam)\n",
    "\n",
    "        images_cut = images.clone()\n",
    "        # å°†ç¬¬ i å¼ å›¾çš„ (y0:y1, x0:x1) åŒºåŸŸæ›¿æ¢ä¸ºç¬¬ idx[i] å¼ å›¾åŒåŒºåŸŸ\n",
    "        images_cut[:, :, y0:y1, x0:x1] = images[idx, :, y0:y1, x0:x1]\n",
    "\n",
    "        # é‡æ–°è®¡ç®— Î»ï¼šå»æ‰çš„åŒºåŸŸæ¯”ä¾‹\n",
    "        area = (x1 - x0) * (y1 - y0)\n",
    "        lam_adj = 1. - area / (W * H)\n",
    "\n",
    "        mixed_labels = lam_adj * labels + (1. - lam_adj) * labels[idx]\n",
    "        return images_cut, mixed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channel, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        # é€šé“æ³¨æ„åŠ›\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "        # ç©ºé—´æ³¨æ„åŠ›\n",
    "        self.conv_spatial = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # é€šé“æ³¨æ„åŠ›\n",
    "        avg_out = self.mlp(self.avg_pool(x))\n",
    "        max_out = self.mlp(self.max_pool(x))\n",
    "        x = x * self.sigmoid_channel(avg_out + max_out)\n",
    "        # ç©ºé—´æ³¨æ„åŠ›\n",
    "        avg_map = x.mean(dim=1, keepdim=True)\n",
    "        max_map, _ = x.max(dim=1, keepdim=True)\n",
    "        x = x * self.sigmoid_spatial(self.conv_spatial(torch.cat([avg_map, max_map], dim=1)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # ç”¨ size å‚æ•°å–ä»£ height & width\n",
    "            A.RandomResizedCrop(\n",
    "                size=(Config.img_size, Config.img_size),\n",
    "                scale=(0.8, 1.0),\n",
    "                ratio=(0.9, 1.1),\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.Rotate(limit=15, p=0.3),\n",
    "            #A.ColorJitter(\n",
    "            #    brightness=0.2, contrast=0.2,\n",
    "            #    saturation=0.2, hue=0.1, p=0.5\n",
    "            #),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=8, max_height=16, max_width=16,\n",
    "                min_holes=1, min_height=8, min_width=8, p=0.3\n",
    "            ),\n",
    "            #A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "            # å†ä¿è¯è¾“å‡ºå°ºå¯¸\n",
    "            A.Resize(\n",
    "                height=Config.img_size,\n",
    "                width=Config.img_size\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(\n",
    "                height=Config.img_size,\n",
    "                width=Config.img_size\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class TumorClassifierCBAM(nn.Module):\n",
    "    def __init__(self, dropout_p=0.7):\n",
    "        super().__init__()\n",
    "        # 1) é¢„è®­ç»ƒ EfficientNet-B0ï¼Œä¸è¦å®ƒçš„åˆ†ç±»å¤´\n",
    "        backbone = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        self.features = backbone.features  # [B,1280,H',W']\n",
    "        \n",
    "        # 2) åœ¨ä¸»å¹²æœ€åæ’ä¸€ä¸ª CBAM\n",
    "        self.cbam = CBAM(channel=1280, reduction=16, kernel_size=7)\n",
    "        \n",
    "        # 3) å…¨å±€æ± åŒ–\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 4) åˆ†ç±»å¤´ï¼šBatchNorm1d -> Dropout -> Linear\n",
    "        in_feats = backbone.classifier[1].in_features  # =1280\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_feats),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_feats, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)     # [B,1280,H',W']\n",
    "        x = self.cbam(x)         # åŠ å…¥æ³¨æ„åŠ›æœºåˆ¶\n",
    "        x = self.global_pool(x)  # [B,1280,1,1]\n",
    "        x = x.flatten(1)         # [B,1280]\n",
    "        x = self.classifier(x)   # [B,1]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    äºŒåˆ†ç±» Focal Loss.\n",
    "    logits: ç½‘ç»œåŸå§‹è¾“å‡ºï¼Œshape [B,1] æˆ– [B]\n",
    "    targets: 0/1 æ ‡ç­¾ï¼Œshape [B,1] æˆ– [B]\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # flatten\n",
    "        if logits.dim()>1:\n",
    "            logits = logits.view(-1)\n",
    "        targets = targets.view(-1).float()\n",
    "        # 1) å…ˆç®— BCE\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        probas  = torch.sigmoid(logits)\n",
    "        # 2) p_t\n",
    "        p_t = probas * targets + (1 - probas) * (1 - targets)\n",
    "        # 3) Î± å¹³è¡¡å› å­\n",
    "        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        # 4) (1âˆ’p_t)^Î³\n",
    "        modulating_factor = (1 - p_t).pow(self.gamma)\n",
    "        loss = alpha_factor * modulating_factor * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images = images.to(Config.device)\n",
    "\n",
    "\n",
    "        labels = labels.to(Config.device).float()\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)  # åªåœ¨ [B] -> [B,1] æ—¶åŠ è¿™ä¸€ç»´\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)        # [B,1]\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ac11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(Config.device)\n",
    "            labels = labels.to(Config.device).float().unsqueeze(1)\n",
    "            \n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "            all_preds.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy().ravel())\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # äºŒåˆ†ç±»é˜ˆå€¼0.5\n",
    "    pred_binary = (all_preds > 0.5).astype(int)\n",
    "    f1 = f1_score(all_labels, pred_binary)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(loader), f1, auc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# è¯»å– CSV æ ‡ç­¾\n",
    "full_df = pd.read_csv(Config.label_csv)\n",
    "\n",
    "# ä¸‰åˆ†æ³•åˆ’åˆ† train / val / test\n",
    "train_df, tmp_df = train_test_split(\n",
    "    full_df,\n",
    "    test_size=0.3,\n",
    "    stratify=full_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=tmp_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "\n",
    "print(f\"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š\\n{train_df['label'].value_counts()}\")\n",
    "print(f\"éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒï¼š\\n{val_df['label'].value_counts()}\")\n",
    "print(f\"æµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒï¼š\\n{test_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mix_mode = \"mixup\"  # å¯é€‰: \"none\", \"mixup\", \"cutmix\"\n",
    "if use_mix_mode.lower() in [\"cutmix\", \"mixup\"]:\n",
    "    # ä½¿ç”¨MixUp/CutMixæ—¶ï¼Œä¸ä½¿ç”¨WeightedRandomSampler\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,  # å¯ä»¥shuffle\n",
    "        num_workers=Config.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "else:\n",
    "    # ä¸ä½¿ç”¨MixUp/CutMixæ—¶ï¼Œä½¿ç”¨WeightedRandomSampler\n",
    "    class_counts = train_df['label'].value_counts().to_dict()\n",
    "    weights = train_df['label'].map(lambda x: 1.0 / class_counts[x]).values\n",
    "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        sampler=sampler,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "print(f\"Mix mode={use_mix_mode}, shuffle_train={shuffle_train}\")\n",
    "\n",
    "# æ„å»º Dataset\n",
    "train_dataset = TumorDataset(train_df, Config.data_dir, train=True)\n",
    "val_dataset   = TumorDataset(val_df,   Config.data_dir, train=False)\n",
    "test_dataset  = TumorDataset(test_df,  Config.data_dir, train=False)\n",
    "\n",
    "# æ„å»º DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# åœ¨æ„å»º train_loader ä¹‹å‰ï¼ŒåŠ ä¸€æ®µè®¡ç®—æ¯ä¸ªæ ·æœ¬æƒé‡çš„ä»£ç ï¼š\n",
    "class_counts = train_df['label'].value_counts().to_dict()  \n",
    "# e.g. {0: 9000, 1: 1000}\n",
    "weights = train_df['label'].map(lambda x: 1.0 / class_counts[x]).values\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "# ç„¶åæŠŠ train_loader æ”¹æˆï¼š\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,            # ç”¨ sampler æ—¶ä¸è¦å† shuffle\n",
    "    sampler=sampler,\n",
    "    num_workers=Config.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "print(\"åˆå§‹åŒ–æ¨¡å‹ä¸­...\")\n",
    "model = TumorClassifierCBAM(dropout_p=0.5).to(Config.device)\n",
    "print(\"æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=Config.lr,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "criterion = FocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
    "early_stopper = EarlyStopping(patience=5,mode='max')\n",
    "scaler = GradScaler()\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_f1': []}\n",
    "best_auc = 0\n",
    "best_thresh = 0.5  # ä¼šåœ¨è®­ç»ƒä¸­æ›´æ–°\n",
    "\n",
    "# æ˜¾ç¤ºè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ\n",
    "train_labels = train_df['label']\n",
    "print(f\"å½“å‰è®­ç»ƒé›†å›¾åƒåˆ†å¸ƒï¼šæ­£å¸¸ç±» {(train_labels == 0).sum()}ï¼Œè‚¿ç˜¤ç±» {(train_labels == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a336c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€”â€” è®­ç»ƒå¾ªç¯ï¼šåªç”¨ Val AUC æ—©åœï¼Œä¸åœ¨æ¯è½®ä¸­åšé˜ˆå€¼æœç´¢ â€”â€” \n",
    "\n",
    "best_auc     = 0.0\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n",
    "use_mixup = use_mix_mode.lower() in [\"cutmix\", \"mixup\"]\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"\\nğŸ“˜ Epoch {epoch+1}/{Config.epochs}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler, use_mixup)\n",
    "    \n",
    "    # æ ¹æ®evaluateå‡½æ•°çš„å®é™…è¿”å›å€¼è°ƒæ•´\n",
    "    if use_mixup:\n",
    "        val_loss, preds, targets = evaluate(model, val_loader, criterion)\n",
    "        val_auc = roc_auc_score(targets, preds)\n",
    "        val_f1 = f1_score(targets, (preds > 0.5).astype(int))\n",
    "    else:\n",
    "        val_loss, val_f1, val_auc, preds, targets = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    # æ‰“å°æŒ‡æ ‡ï¼ˆä»…ç”¨ AUC è¯„ä¼°ï¼‰\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # è®°å½•å†å²\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "\n",
    "    # ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆæŒ‰ AUCï¼‰\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), os.path.join(Config.save_dir, \"best_model.pth\"))\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "    # æ—©åœæ£€æŸ¥ï¼ˆç›‘æ§ AUCï¼‰\n",
    "    early_stopper(val_auc)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# â€”â€” è®­ç»ƒç»“æŸåï¼Œå†åšä¸€æ¬¡æ•´ä½“é˜ˆå€¼æœç´  & æœ€ç»ˆè¯„ä¼° â€”â€” \n",
    "\n",
    "# åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\n",
    "model.load_state_dict(torch.load(os.path.join(Config.save_dir, \"best_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# åœ¨æ•´ä¸ªéªŒè¯é›†ä¸Šè®¡ç®—æ¦‚ç‡\n",
    "_, preds, targets = evaluate(model, val_loader, criterion)\n",
    "preds = preds.ravel()\n",
    "targets = targets.ravel()\n",
    "\n",
    "# æœç´¢æœ€ä½³ F1 é˜ˆå€¼\n",
    "best_f1, best_thresh = 0.0, 0.5\n",
    "for t in np.arange(0.1, 0.9, 0.01):\n",
    "    f1 = f1_score(targets, (preds >= t).astype(int))\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thresh = f1, t\n",
    "\n",
    "# æœ€ç»ˆæŒ‰æœ€ä½³é˜ˆå€¼è®¡ç®—æŒ‡æ ‡\n",
    "final_preds = (preds >= best_thresh).astype(int)\n",
    "final_acc  = accuracy_score(targets, final_preds)\n",
    "final_auc  = roc_auc_score(targets, preds)\n",
    "tn, fp, fn, tp = confusion_matrix(targets, final_preds).ravel()\n",
    "final_spec = tn/(tn+fp)\n",
    "final_sens = tp/(tp+fn)\n",
    "\n",
    "print(\"\\n=== æœ€ç»ˆéªŒè¯é›†è¯„ä¼° ===\")\n",
    "print(f\"Best F1 Threshold: {best_thresh:.2f}\")\n",
    "print(f\"ACC:         {final_acc:.4f}\")\n",
    "print(f\"F1-score:    {best_f1:.4f}\")\n",
    "print(f\"AUC:         {final_auc:.4f}\")\n",
    "print(f\"Specificity: {final_spec:.4f}\")\n",
    "print(f\"Sensitivity: {final_sens:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc04711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# â€”â€” åœ¨ä¸‰åˆ†æ³•åˆ’åˆ†ååŠ å…¥ä»¥ä¸‹æ£€æŸ¥ â€”â€” \n",
    "train_files = set(train_df['filename'].tolist())\n",
    "val_files   = set(val_df  ['filename'].tolist())\n",
    "test_files  = set(test_df ['filename'].tolist())\n",
    "\n",
    "# æ£€æŸ¥ä¸¤ä¸¤äº¤é›†æ˜¯å¦ä¸ºç©º\n",
    "assert train_files.isdisjoint(val_files),  \\\n",
    "    f\"æ•°æ®æ³„éœ²ï¼štrain ä¸ val æœ‰ {len(train_files & val_files)} å¼ å›¾é‡å¤\"\n",
    "assert train_files.isdisjoint(test_files), \\\n",
    "    f\"æ•°æ®æ³„éœ²ï¼štrain ä¸ test æœ‰ {len(train_files & test_files)} å¼ å›¾é‡å¤\"\n",
    "assert val_files.isdisjoint(test_files),   \\\n",
    "    f\"æ•°æ®æ³„éœ²ï¼šval   ä¸ test æœ‰ {len(val_files & test_files)} å¼ å›¾é‡å¤\"\n",
    "\n",
    "print(\"âœ… åˆ’åˆ†æ ¡éªŒé€šè¿‡ï¼Œtrain/val/test ä¸‰ä¸ªé›†åˆäº’ä¸é‡å ã€‚\")\n",
    "\n",
    "# æ‰‹åŠ¨è®¾ç½®è·¯å¾„å’Œå‚æ•°\n",
    "label_csv = r\"D:\\Leko\\medical_model\\task1\\dataset\\labels.csv\"\n",
    "img_dir   = r\"D:\\Leko\\medical_model\\task1\\dataset\\images\"\n",
    "seed = 42\n",
    "\n",
    "# 1. è¯»å–æ ‡ç­¾å¹¶å»é‡\n",
    "df = pd.read_csv(label_csv).drop_duplicates(subset=['filename'])\n",
    "\n",
    "# 2. ä¸‰åˆ†æ³•åˆ’åˆ†\n",
    "train_df, tmp_df = train_test_split(\n",
    "    df, test_size=0.3, stratify=df['label'], random_state=seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df, test_size=0.5, stratify=tmp_df['label'], random_state=seed\n",
    ")\n",
    "\n",
    "# 3. å®šä¹‰æ˜¾ç¤ºå‡½æ•°\n",
    "def show_samples(df, name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    for ax, label in zip(axes, [0, 1]):\n",
    "        subset = df[df['label'] == label]\n",
    "        fname = random.choice(subset['filename'].tolist())\n",
    "        img = Image.open(os.path.join(img_dir, fname)).convert('RGB')\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{name} label={label}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. æ˜¾ç¤ºä¸‰ä¸ªé›†åˆçš„æ ·æœ¬\n",
    "show_samples(train_df, \"Train\")\n",
    "show_samples(val_df, \"Val\")\n",
    "show_samples(test_df, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "model.load_state_dict(torch.load(os.path.join(Config.save_dir, \"best_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "test_loss, test_preds, test_targets = evaluate(model, test_loader, criterion)\n",
    "test_auc  = roc_auc_score(test_targets, test_preds)\n",
    "test_f1   = f1_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "test_acc  = accuracy_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "\n",
    "# è®¡ç®—æ··æ·†çŸ©é˜µå¹¶æå–æŒ‡æ ‡\n",
    "cm = confusion_matrix(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn + 1e-8)  # True Positive Rate\n",
    "specificity = tn / (tn + fp + 1e-8)  # True Negative Rate\n",
    "\n",
    "# æ‰“å°æ‰€æœ‰æŒ‡æ ‡\n",
    "print(f\"ğŸ§ª Test Loss: {test_loss:.4f} | Test AUC: {test_auc:.4f} | \"\n",
    "      f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "print(f\"ğŸ§ª Test Sensitivity (Recall for tumor): {sensitivity:.4f} | \"\n",
    "      f\"Test Specificity (Recall for normal): {specificity:.4f}\")\n",
    "\n",
    "# ç»˜åˆ¶æµ‹è¯•é›†æ··æ·†çŸ©é˜µ\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal\", \"Tumor\"],\n",
    "            yticklabels=[\"Normal\", \"Tumor\"])\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# ä¿å­˜æµ‹è¯•é›†é¢„æµ‹ç»“æœ\n",
    "test_df = test_df.copy()\n",
    "test_df['pred_prob']  = test_preds\n",
    "test_df['pred_label'] = (test_preds >= best_thresh).astype(int)\n",
    "test_df.to_csv(os.path.join(Config.save_dir, \"test_predictions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./output/best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "infer_transform = get_transforms(train=False)\n",
    "\n",
    "\n",
    "def predict_image(image_path, model, best_thresh=0.5):\n",
    "    # ç¡®ä¿æ¨¡å‹å·²ç»åˆå§‹åŒ–å’ŒåŠ è½½\n",
    "    if not hasattr(predict_image, 'model_loaded'):\n",
    "        model = TumorClassifierCBAM(dropout_p=0.3).to(Config.device)\n",
    "        model.load_state_dict(torch.load(\"./output/best_model.pth\"))\n",
    "        model.eval()\n",
    "        predict_image.model_loaded = True\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    transformed = infer_transform(image=image_np)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(Config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        label = 1 if prob >= best_thresh else 0  # ä½¿ç”¨è®­ç»ƒæ—¶çš„æœ€ä½³é˜ˆå€¼\n",
    "\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"é¢„æµ‹æ ‡ç­¾: {'è‚¿ç˜¤' if label==1 else 'æ­£å¸¸'}\\né¢„æµ‹æ¦‚ç‡: {prob:.4f}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return prob, label\n",
    "\n",
    "\n",
    "predict_image(\"D:\\\\Leko\\\\test1.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test2.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test3.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test4.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## å¤–éƒ¨éªŒè¯é›†è¯„ä¼° â€” å¸¦å»é»‘è¾¹ & å±…ä¸­è¡¥é½é¢„å¤„ç†\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# â€”â€” æ–°å¢ï¼šå»é»‘è¾¹ + å±…ä¸­è¡¥é½é¢„å¤„ç†å‡½æ•° â€”â€” \n",
    "def preprocess_image(img: Image.Image, black_threshold=10) -> Image.Image:\n",
    "    \"\"\"\n",
    "    å»é™¤é»‘è¾¹å¹¶å±…ä¸­è¡¥é½\n",
    "    black_threshold: åƒç´ å€¼å°äºæ­¤å€¼è®¤ä¸ºæ˜¯é»‘è‰²\n",
    "    \"\"\"\n",
    "    arr = np.array(img)\n",
    "    \n",
    "    # å¤„ç†ç°åº¦å’Œå½©è‰²å›¾åƒ\n",
    "    if arr.ndim == 3:\n",
    "        # å½©è‰²å›¾åƒï¼šä»»ä¸€é€šé“å¤§äºé˜ˆå€¼å°±ä¸æ˜¯é»‘è‰²\n",
    "        mask = np.any(arr > black_threshold, axis=2)\n",
    "    else:\n",
    "        # ç°åº¦å›¾åƒ\n",
    "        mask = arr > black_threshold\n",
    "    \n",
    "    # æ‰¾åˆ°éé»‘è‰²åŒºåŸŸçš„è¾¹ç•Œ\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size > 0:\n",
    "        y0, x0 = coords.min(axis=0)\n",
    "        y1, x1 = coords.max(axis=0)\n",
    "        img = img.crop((x0, y0, x1 + 1, y1 + 1))\n",
    "    \n",
    "    # å±…ä¸­è¡¥é½æˆæ­£æ–¹å½¢\n",
    "    w, h = img.size\n",
    "    if w > 0 and h > 0:  # ç¡®ä¿å°ºå¯¸æœ‰æ•ˆ\n",
    "        max_wh = max(w, h)\n",
    "        pad_w = (max_wh - w) // 2\n",
    "        pad_h = (max_wh - h) // 2\n",
    "        padding = (pad_w, pad_h, max_wh - w - pad_w, max_wh - h - pad_h)\n",
    "        img = ImageOps.expand(img, padding, fill=0)\n",
    "    \n",
    "    return img\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform)\n",
    "        # ç¡®ä¿ç±»åˆ«æ˜ å°„ä¸è®­ç»ƒæ—¶ä¸€è‡´\n",
    "        # å‡è®¾æ–‡ä»¶å¤¹åä¸º 'normal' å’Œ 'tumor'\n",
    "        if 'normal' in self.classes and 'tumor' in self.classes:\n",
    "            # é‡æ–°æ˜ å°„ï¼šnormal->0, tumor->1\n",
    "            self.class_to_idx = {'normal': 0, 'tumor': 1}\n",
    "            # æ›´æ–°targets\n",
    "            old_to_new = {old_idx: self.class_to_idx[class_name] \n",
    "                         for class_name, old_idx in self.class_to_idx.items()}\n",
    "            self.targets = [old_to_new.get(t, t) for t in self.targets]\n",
    "# 1. é…ç½®\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ext_root = r'D:\\Leko\\testset\\testset1(8)'\n",
    "best_model_path = os.path.join(Config.save_dir, \"best_model.pth\")\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "# 2. é¢„å¤„ç†ï¼ˆåŠ ä¸Š preprocess_imageï¼‰\n",
    "ext_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: preprocess_image(img)),  #  æ–°å¢\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485,0.456,0.406),\n",
    "                         std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "# 3. æ„å»º DataLoader\n",
    "ext_dataset = ImageFolder(root=ext_root, transform=ext_transform)\n",
    "print(\"External classes:\", ext_dataset.classes)\n",
    "ext_loader = DataLoader(\n",
    "    ext_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(f\"å¤–éƒ¨éªŒè¯é›†: {len(ext_dataset)} å¼ å›¾, {len(ext_loader)} ä¸ª batch\")\n",
    "\n",
    "# 4. åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡\n",
    "model = TumorClassifierCBAM(dropout_p=0.8).to(Config.device)\n",
    "state = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(\"âœ… Loaded best_model.pth\")\n",
    "# %% [markdown]\n",
    "# ## å¤–éƒ¨éªŒè¯é›†è¯„ä¼° â€” å±•ç¤ºæ¯ä¸ª label ä¸‹ 3 å¼ ç»è¿‡ transform çš„å›¾åƒ\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# å…ˆä» ext_dataset é‡Œå„æŠ½ 3 å¼ \n",
    "samples_per_class = {0: [], 1: []}\n",
    "indices = list(range(len(ext_dataset)))\n",
    "random.shuffle(indices)\n",
    "for idx in indices:\n",
    "    img, label = ext_dataset[idx]  # å·²ç»åšäº† preprocess + Resize + ToTensor + Normalize\n",
    "    if len(samples_per_class[label]) < 3:\n",
    "        samples_per_class[label].append(img)\n",
    "    if len(samples_per_class[0]) == 3 and len(samples_per_class[1]) == 3:\n",
    "        break\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªåå½’ä¸€åŒ–ï¼Œç”¨äºå¯è§†åŒ–\n",
    "inv_norm = transforms.Normalize(\n",
    "    mean=[-m/s for m,s in zip((0.485,0.456,0.406),(0.229,0.224,0.225))],\n",
    "    std=[1/s for s in (0.229,0.224,0.225)]\n",
    ")\n",
    "\n",
    "# ç»˜å›¾\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for cls, row in samples_per_class.items():\n",
    "    for i, tensor_img in enumerate(row):\n",
    "        img_vis = inv_norm(tensor_img)                 # å…ˆåå½’ä¸€åŒ–\n",
    "        img_vis = img_vis.permute(1,2,0).clamp(0,1)    # HWC\n",
    "        axes[cls, i].imshow(img_vis.numpy())\n",
    "        axes[cls, i].set_title(f\"label={cls}\")\n",
    "        axes[cls, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. æ¨ç†\n",
    "all_probs, all_labels = [], []\n",
    "with torch.inference_mode():\n",
    "    for imgs, labels in tqdm(ext_loader, desc=\"External Inference\"):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        logits = model(imgs).view(-1)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_probs  = np.array(all_probs)\n",
    "all_labels = np.array(all_labels).astype(int)\n",
    "\n",
    "# 6. è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡\n",
    "preds = (all_probs >= 0.5).astype(int)\n",
    "acc  = accuracy_score(all_labels, preds)\n",
    "f1   = f1_score(all_labels, preds)\n",
    "auc  = roc_auc_score(all_labels, all_probs)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, preds).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print(\"\\n=== å¤–éƒ¨éªŒè¯é›†è¯„ä¼°ç»“æœ ===\")\n",
    "print(f\"æ ·æœ¬æ€»æ•°: {len(ext_dataset)} \"\n",
    "      f\"(normal={ext_dataset.targets.count(0)}, tumor={ext_dataset.targets.count(1)})\")\n",
    "print(f\"ACC:         {acc:.4f}\")\n",
    "print(f\"F1-score:    {f1:.4f}\")\n",
    "print(f\"AUC:         {auc:.4f}\")\n",
    "print(f\"Specificity: {spec:.4f}\")\n",
    "print(f\"Sensitivity: {sens:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
